Code :
import java.io.IOException;
import java.util.StringTokenizer;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

public class WordCount {

  public static class TokenizerMapper
       extends Mapper<Object, Text, Text, IntWritable>{

    private final static IntWritable one = new IntWritable(1);
    private Text word = new Text();

    public void map(Object key, Text value, Context context
                    ) throws IOException, InterruptedException {
      StringTokenizer itr = new StringTokenizer(value.toString());
      while (itr.hasMoreTokens()) {
        word.set(itr.nextToken());
        context.write(word, one);
      }
    }
  }

  public static class IntSumReducer
       extends Reducer<Text,IntWritable,Text,IntWritable> {
    private IntWritable result = new IntWritable();

    public void reduce(Text key, Iterable<IntWritable> values,
                       Context context
                       ) throws IOException, InterruptedException {
      int sum = 0;
      for (IntWritable val : values) {
        sum += val.get();
      }
      result.set(sum);
      context.write(key, result);
    }
  }

  public static void main(String[] args) throws Exception {
    Configuration conf = new Configuration();
    Job job = Job.getInstance(conf, "word count");
    job.setJarByClass(WordCount.class);
    job.setMapperClass(TokenizerMapper.class);
    job.setCombinerClass(IntSumReducer.class);
    job.setReducerClass(IntSumReducer.class);
    job.setOutputKeyClass(Text.class);
    job.setOutputValueClass(IntWritable.class);
    FileInputFormat.addInputPath(job, new Path(args[0]));
    FileOutputFormat.setOutputPath(job, new Path(args[1]));
    System.exit(job.waitForCompletion(true) ? 0 : 1);
  }
}

Commands :


[cloudera@quickstart ~]$ ls
cloudera-manager  Desktop    Downloads  enterprise-deployment.json  f.txt   kerberos  Music    Pictures  Templates  wordcount.jar
cm_api.py         Documents  eclipse    express-deployment.json     f.txt~  lib       parcels  Public    Videos     workspace
[cloudera@quickstart ~]$ pwd
/home/cloudera
[cloudera@quickstart ~]$ cat > /home/cloudera/Processfile1.txt
asd    
asd
asd
sdf
sdf
^Z
[1]+  Stopped                 cat > /home/cloudera/Processfile1.txt
[cloudera@quickstart ~]$ cat > /home/cloudera/Processfile1.txt
asd
asd
asd
dfg
dfg
fgh
ghjk
^Z
[2]+  Stopped                 cat > /home/cloudera/Processfile1.txt
[cloudera@quickstart ~]$ cat /home/cloudera/Processfile1.txt
asd
asd
asd
dfg
dfg
fgh
ghjk
[cloudera@quickstart ~]$ hdfs dfs -ls
[cloudera@quickstart ~]$ hdfs dfs -ls/
-ls/: Unknown command
[cloudera@quickstart ~]$ hdfs dfs -ls /
Found 6 items
drwxrwxrwx   - hdfs  supergroup          0 2017-10-23 09:15 /benchmarks
drwxr-xr-x   - hbase supergroup          0 2024-05-03 01:02 /hbase
drwxr-xr-x   - solr  solr                0 2017-10-23 09:18 /solr
drwxrwxrwt   - hdfs  supergroup          0 2024-03-06 22:27 /tmp
drwxr-xr-x   - hdfs  supergroup          0 2017-10-23 09:17 /user
drwxr-xr-x   - hdfs  supergroup          0 2017-10-23 09:17 /var
[cloudera@quickstart ~]$ hdfs dfs -mkdir /Inputfolder1
[cloudera@quickstart ~]$ hdfs dfs -put /home/coludera/Processfile1.txt /Inputfolder1
put: `/home/coludera/Processfile1.txt': No such file or directory
[cloudera@quickstart ~]$ hdfs dfs -mkdir /home/cloudera/Inputfolder1
mkdir: `/home/cloudera/Inputfolder1': No such file or directory
[cloudera@quickstart ~]$ hdfs dfs -mkdir / Inputfolder1
mkdir: `/': File exists
[cloudera@quickstart ~]$ ^C
[cloudera@quickstart ~]$ hdfs dfs -mkdir /inputfolder1
[cloudera@quickstart ~]$ hdfs dfs -put /home/cloudera/Processfile1.txt /inputfolder1/
[cloudera@quickstart ~]$ hdfs dfs -cat /inputfolder1/Processfile1.txt
asd
asd
asd
dfg
dfg
fgh
ghjk
[cloudera@quickstart ~]$ hadoop jar /home/cloudera/wordcount.jar wordcount /inputfolder1/Processfile1.txt /out1
24/05/03 02:14:53 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
24/05/03 02:14:54 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
24/05/03 02:14:55 INFO input.FileInputFormat: Total input paths to process : 1
24/05/03 02:14:55 INFO mapreduce.JobSubmitter: number of splits:1
24/05/03 02:14:56 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1714717182485_0011
24/05/03 02:14:56 INFO impl.YarnClientImpl: Submitted application application_1714717182485_0011
24/05/03 02:14:56 INFO mapreduce.Job: The url to track the job: http://quickstart.cloudera:8088/proxy/application_1714717182485_0011/
24/05/03 02:14:56 INFO mapreduce.Job: Running job: job_1714717182485_0011
24/05/03 02:15:05 INFO mapreduce.Job: Job job_1714717182485_0011 running in uber mode : false
24/05/03 02:15:05 INFO mapreduce.Job:  map 0% reduce 0%
24/05/03 02:15:12 INFO mapreduce.Job:  map 100% reduce 0%
24/05/03 02:15:19 INFO mapreduce.Job:  map 100% reduce 100%
24/05/03 02:15:19 INFO mapreduce.Job: Job job_1714717182485_0011 completed successfully
24/05/03 02:15:19 INFO mapreduce.Job: Counters: 49
	File System Counters
		FILE: Number of bytes read=47
		FILE: Number of bytes written=286797
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=155
		HDFS: Number of bytes written=25
		HDFS: Number of read operations=6
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=4812
		Total time spent by all reduces in occupied slots (ms)=4011
		Total time spent by all map tasks (ms)=4812
		Total time spent by all reduce tasks (ms)=4011
		Total vcore-milliseconds taken by all map tasks=4812
		Total vcore-milliseconds taken by all reduce tasks=4011
		Total megabyte-milliseconds taken by all map tasks=4927488
		Total megabyte-milliseconds taken by all reduce tasks=4107264
	Map-Reduce Framework
		Map input records=7
		Map output records=7
		Map output bytes=57
		Map output materialized bytes=47
		Input split bytes=126
		Combine input records=7
		Combine output records=4
		Reduce input groups=4
		Reduce shuffle bytes=47
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=112
		CPU time spent (ms)=950
		Physical memory (bytes) snapshot=344256512
		Virtual memory (bytes) snapshot=3016970240
		Total committed heap usage (bytes)=226365440
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=29
	File Output Format Counters 
		Bytes Written=25
[cloudera@quickstart ~]$ hdfs dfs -ls /out1
Found 2 items
-rw-r--r--   1 cloudera supergroup          0 2024-05-03 02:15 /out1/_SUCCESS
-rw-r--r--   1 cloudera supergroup         25 2024-05-03 02:15 /out1/part-r-00000
[cloudera@quickstart ~]$ hdfs dfs -ls /out1/part-r-00000
-rw-r--r--   1 cloudera supergroup         25 2024-05-03 02:15 /out1/part-r-00000
[cloudera@quickstart ~]$ hdfs dfs -cat /out1/part-r-00000
asd	3
dfg	2
fgh	1
ghjk	1
[cloudera@quickstart ~]$ 
